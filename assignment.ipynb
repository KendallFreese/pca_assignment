{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rb5QQRb7BMWg"
      },
      "source": [
        "## PCA and Text Analysis\n",
        "\n",
        "This assignment involves processing real e-mails, some of which are scams.\n",
        "\n",
        "Fair warning: Some of these scam e-mails have offensive content. If you start reading the e-mail text or the token data, you might read something offensive. If that's a problem, feel free to e-mail me, and we can talk about it and discuss how to proceed with alternative tasks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idHEenWdBMWi"
      },
      "source": [
        "### Q1.\n",
        "\n",
        "**Tokens**: The individual words or symbols that create text data like emails. Natural Language Processing is primarily about analyzing the frequency and co-occurrence of tokens.\n",
        "\n",
        "I aggregated all the emails into a single vector, and removed the punctuation and very common words (e.g. \"the\"). Run the below code chunk to open it, and use the Counter class to look at the most common words:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HftVc760BMWi"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open('data/all_tokens.pickle', 'rb') as file:\n",
        "    all_tokens = pickle.load(file)\n",
        "\n",
        "from collections import Counter\n",
        "token_count = Counter(all_tokens)\n",
        "token_freq = token_count.most_common()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hppSOGN6BMWi"
      },
      "source": [
        "Plot a histogram of the occurrences of tokens.\n",
        "\n",
        "What do you notice about the frequency of occurrence of different tokens? How does it look?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sst43EdzBMWj"
      },
      "outputs": [],
      "source": [
        "# histogram plot"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The frequency of occurrence of different tokens is ______. It looks ______."
      ],
      "metadata": {
        "id": "bvX5i8UmBgP4"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1hvko_PBMWj"
      },
      "source": [
        "### Q2.\n",
        "\n",
        "Load `Phishing_clean.parquet`. This is the text from the e-mails broken into the most common 2,711 tokens and one-hot-encoded as features/covariates. So each row is an e-mail, the `Email Type` takes the value 1 if it's a scam and 0 otherwise, and every other column is a word or symbol that occurs in at least 15 e-mails.\n",
        "\n",
        "1. Perform an 80/20 train-test split of the data.\n",
        "2. Run a regression of $y$ on the one-hot-encoded emails. What is the $R^2$ on the test set? On the training set?\n",
        "3. What words have the largest coefficients in absolute value and most strongly influence predictions?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tE3RpaC9BMWj"
      },
      "outputs": [],
      "source": [
        "# 80/20 train-test split on data\n",
        "\n",
        "\n",
        "# regression of y on on-hot-encoded email\n",
        "\n",
        "\n",
        "# words w/ largest coefficients in absolute value and strongly influence predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The words that have the largest coefficients and have the strongtest impact on predictions are _______."
      ],
      "metadata": {
        "id": "x1S8El8IBzis"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mLo_bg9DBMWj"
      },
      "source": [
        "### Q3.\n",
        "\n",
        "Take the matrix of one-hot-encoded tokens (the data, less the outcome variable, `Email Type`) and perform a principal components analysis decomposition with two components. Plot the first two principal components in a scatter plot, and hue the points by whether they are a phishing scam or not. Do you notice any patterns?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AHlmD-NGBMWj"
      },
      "outputs": [],
      "source": [
        "# matrix of one-hot-encoded tokens\n",
        "\n",
        "# pca analysis decomp\n",
        "\n",
        "# scatterplot of first 2 components"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I notice multiple patterns. I see that ____."
      ],
      "metadata": {
        "id": "krR5oLw0B_Q_"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KkB85OpDBMWj"
      },
      "source": [
        "### Q4.\n",
        "\n",
        "Run a linear regression of $y$ on the first 2,610 principal components of $X$. What is the $R^2$ on the training and test sets? (I used cross validation to determine that 2,610 was approximately optimal, but not all 2,711 components.)\n",
        "\n",
        "How does this performance compare to the linear regression?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W76eMs6tBMWj"
      },
      "outputs": [],
      "source": [
        "# linear regression of y\n",
        "\n",
        "\n",
        "# R squared on training & test sets\n",
        "\n",
        "# comparison?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This performance compares to the linear regression as it ____."
      ],
      "metadata": {
        "id": "QuSaeQSpCH-e"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPD4sOxABMWk"
      },
      "source": [
        "### Q5.\n",
        "\n",
        "Explain briefly in your own words what the advantage is in using the principal components to run this high-dimensional regression, rather than the original data."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The advantage in using prinicpal components to run a high-dimensional regression as opposed to the original data is that ______."
      ],
      "metadata": {
        "id": "LtOteet2CLUX"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}